{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DeepAR model "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys, os \n",
    "import json \n",
    "import logging \n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Add folder location to Python paths so that packages can be imported \n",
    "p = os.path.abspath('../')\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)\n",
    "    \n",
    "from src.data import open_and_transform_csv2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data transformation \n",
    "\n",
    "For gluonts models, the data needs to be in form of iterable objects. \n",
    "\n",
    "The datasets provided by GluonTS consists of three main members:\n",
    "- train: iterable collection of data entries used for training. Each entry corresponds to one time series\n",
    "- test: iterable collection of data entries used for inference. The test dataset is an extended version of the train dataset that contains a window in the end of each time series that was not seen during training. This window has length equal to the recommended prediction length. \n",
    "- metadata: contains metadata of the dataset such as the frequency of the time series, a recommended prediction horizon, associated features, etc.\n",
    "\n",
    "Moreover, gluonts use \"field_names\", the attributes of the type of data in the train, test and metadata. For instance train has to contain a ``target`` and a ``start`` fields for each entry, but we can add features such as ``feat_static_cat``, ``feat_static_real``, etc. The test has to contain the ``start``, ``target`` and  ``prediction_length`` fields for each entries. \n",
    "\n",
    "\n",
    "The fields are split into three categories: the required ones, the optional ones, and the ones that can be added by the Transformation (explained in a while).\n",
    "\n",
    "#### Required:\n",
    "- start: start date of the time series\n",
    "- target: values of the time series\n",
    "\n",
    "#### Optional:\n",
    "\n",
    "- feat_static_cat: static (over time) categorical features, list with dimension equal to the number of features\n",
    "- feat_static_real: static (over time) real features, list with dimension equal to the number of features\n",
    "- feat_dynamic_cat: dynamic (over time) categorical features, array with shape equal to (number of features, target length)\n",
    "- feat_dynamic_real: dynamic (over time) real features, array with shape equal to (number of features, target length)\n",
    "\n",
    "#### Added by Transformation:\n",
    "- time_feat: time related features such as the month or the day\n",
    "- feat_dynamic_const: expands a constant value feature along the time axis\n",
    "- feat_dynamic_age: age feature, i.e., a feature that its value is small for distant past timestamps and it monotonically increases the more we approach the current timestamp\n",
    "- observed_values: indicator for observed values, i.e., a feature that equals to 1 if the value is observed and 0 if the value is missing\n",
    "- is_pad: indicator for each time step that shows if it is padded (if the length is not enough)\n",
    "- forecast_start: forecast start date\n",
    "\n",
    "Finally, the metadata contains general information about the model. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fieldnames are used to store data\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "[f\"FieldName.{k} = '{v}'\" for k, v in FieldName.__dict__.items() if not k.startswith('_')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spx_daily = open_and_transform_csv2(r'../data/spx_daily.xlsx')\n",
    "spx_daily.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strikes = [40,  60,  80,  90, 100, 110, 120]\n",
    "maturities = [\"6M\", \"1Y\", \"18M\", \"2Y\", \"3Y\"]\n",
    "\n",
    "# Start date\n",
    "start = spx_daily.Dates.min()\n",
    "\n",
    "# Organize the data as gluonts inputs \n",
    "target = []\n",
    "nb_series = 0\n",
    "feat_static_cat = []\n",
    "feat_static_real = []\n",
    "# Initialize the number of steps (this is the # of observations per TS)\n",
    "num_steps =  3230\n",
    "\n",
    "for s in strikes:\n",
    "    for m in maturities: \n",
    "        df_temp = spx_daily[(spx_daily.Strike == s) & (spx_daily.Duration == m)].sort_values(by=\"Dates\")\n",
    "        if num_steps != df_temp.shape[0]: \n",
    "            print(\"There is a TS with different number of observations\")\n",
    "            break\n",
    "        else: \n",
    "            target.append(df_temp.Change_in_implied_vol.values)\n",
    "            nb_series += 1\n",
    "            feat_static_real.append(s)\n",
    "            feat_static_cat.append(m)\n",
    "\n",
    "target, feat_static_real, feat_static_cat = np.array(target), np.array(feat_static_real), np.array(feat_static_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now define the metadata containing the parameters of the dataset\n",
    "metadata = {'num_series': len(strikes)*len(maturities),\n",
    "                      'num_steps': num_steps,\n",
    "                      'prediction_length': 10,\n",
    "                      'freq': '1D',\n",
    "                      'start': [pd.Timestamp(start, freq='1D')\n",
    "                                for _ in range(num_steps)]\n",
    "                     }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metadata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We have 35 TS, each with 3230 observations. \n",
    "# For each TS, the feat_static_real contains the strike, the feat_static_cat contains the maturity. \n",
    "print(type(target), type(feat_static_real), type(feat_static_cat))\n",
    "print(target.shape, feat_static_real.shape, feat_static_cat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feat_static_real, feat_static_cat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "for ts in range(0, 35): \n",
    "    dict1 = {FieldName.TARGET: target[ts, :-metadata['prediction_length']], FieldName.START: start, FieldName.FEAT_STATIC_REAL: feat_static_real[ts]}\n",
    "    list_of_dicts.append(dict1) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_of_dicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "# Create the train dataset\n",
    "train_ds = ListDataset(list_of_dicts, freq=metadata['freq'])\n",
    "print(train_ds)\n",
    "\n",
    "train_entry = next(iter(train_ds))\n",
    "print(f\"Keys of train_ds : {train_entry.keys()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating the test dataset \n",
    "list_of_dicts = []\n",
    "for ts in range(0, 35): \n",
    "    dict1 = {FieldName.TARGET: target[ts], FieldName.START: start, FieldName.FEAT_STATIC_REAL: feat_static_real[ts]}\n",
    "    list_of_dicts.append(dict1) \n",
    "test_ds = ListDataset(list_of_dicts, freq=metadata['freq'])\n",
    "test_ds\n",
    "\n",
    "test_entry = next(iter(test_ds))\n",
    "print(test_entry.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_pandas(train_entry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_pandas(test_entry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gluonts.dataset.util import to_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_series = to_pandas(test_entry)\n",
    "train_series = to_pandas(train_entry)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(20, 8))\n",
    "\n",
    "train_series.plot(ax=ax[0])\n",
    "ax[0].grid(which=\"both\")\n",
    "ax[0].legend([\"train series\"], loc=\"upper left\")\n",
    "\n",
    "test_series.plot(ax=ax[1])\n",
    "ax[1].axvline(train_series.index[-10], color='r') # end of train dataset\n",
    "ax[1].grid(which=\"both\")\n",
    "ax[1].legend([\"test series\", \"end of train series\"], loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Length of forecasting window in test dataset: {len(test_series) - len(train_series)}\")\n",
    "print(f\"Recommended prediction horizon: {metadata['prediction_length']}\")\n",
    "print(f\"Frequency of the time series: {metadata['freq']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models \n",
    "\n",
    "## 1) SimpleFeedForwardEstimator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimator1 = SimpleFeedForwardEstimator(\n",
    "    num_hidden_dimensions=[2],\n",
    "    prediction_length=custom_ds_metadata[\"prediction_length\"],\n",
    "    context_length=custom_ds_metadata[\"num_steps\"],\n",
    "    freq=custom_ds_metadata[\"freq\"],\n",
    "    trainer=Trainer(ctx=\"cpu\",\n",
    "                    epochs=5,\n",
    "                    learning_rate=1e-10,\n",
    "                    num_batches_per_epoch=1\n",
    "                   )\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor1 = estimator1.train(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_ds,  # test dataset\n",
    "    predictor=predictor,  # predictor\n",
    "    num_samples=100,  # number of sample paths we want for evaluation\n",
    ")\n",
    "\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)\n",
    "\n",
    "ts_entry = tss[0]\n",
    "np.array(ts_entry[:5]).reshape(-1,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test_entry = next(iter(test_ds))\n",
    "dataset_test_entry['target'][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first entry of the forecast list\n",
    "forecast_entry = forecasts[0]\n",
    "forecast_entry"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_prob_forecasts(ts_entry, forecast_entry):\n",
    "    plot_length = 50\n",
    "    prediction_intervals = (50.0, 90.0)\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series\n",
    "    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.legend(legend, loc=\"upper left\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_prob_forecasts(ts_entry, forecast_entry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "print(json.dumps(agg_metrics, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) DeepAR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gluonts.model.deepar import DeepAREstimator\n",
    "\n",
    "estimator = DeepAREstimator(\n",
    "    prediction_length=custom_ds_metadata[\"prediction_length\"],\n",
    "    context_length=100,\n",
    "    freq=custom_ds_metadata[\"freq\"]\n",
    ")\n",
    "\n",
    "predictor = estimator.train(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_ds,  # test dataset\n",
    "    predictor=predictor,  # predictor\n",
    "    num_samples=100,  # number of sample paths we want for evaluation\n",
    ")\n",
    "\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast_entry = forecasts[0]\n",
    "\n",
    "plot_prob_forecasts(ts_entry, forecast_entry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(json.dumps(agg_metrics, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}